<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Xuhui  Zhou | publications</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Xuhui</span>   Zhou
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">Publications by categories in reversed chronological order. Generated by jekyll-scholar (* means equal contribution).</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">EACL</abbr>
    
  
  </div>

  <div id="zhou-etal-2020-debiasing" class="col-sm-8">
    
      <div class="title">Challenges in Automated Debiasing for Toxic Language Detection</div>
      <div class="author">
        
          
            
              
                <em>Zhou, Xuhui</em>,
              
            
          
        
          
            
              
                
                  Sap, Maarten,
                
              
            
          
        
          
            
              
                
                  Swayamdipta, Swabha,
                
              
            
          
        
          
            
              
                
                  Choi, Yejin,
                
              
            
          
        
          
            
              
                
                  and Smith, Noah A.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In EACL</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://arxiv.org/abs/2102.00086" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
      <a href="https://github.com/XuhuiZhou/Toxic_Debias" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <div id="azhou-etal-2020-debiasing" style="display: none;">
    <pre>@inproceedings{zhou-etal-2020-debiasing,
  title = {Challenges in Automated Debiasing for Toxic Language Detection},
  author = {Zhou, Xuhui and Sap, Maarten and Swayamdipta, Swabha and Choi, Yejin and Smith, Noah A.},
  booktitle = {EACL},
  abbr = {EACL},
  html = {https://arxiv.org/abs/2102.00086},
  code = {https://github.com/XuhuiZhou/Toxic_Debias},
  year = {2021}
}
</pre>
    </div>
    <script>
    function toggleBibtexzhou-etal-2020-debiasing(parameter) {
        var x= document.getElementById('azhou-etal-2020-debiasing');
        if (x.style.display === 'none') {
            x.style.display = 'block';
        } else {
            x.style.display = 'none';
        }
    }
    </script>

  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">BlackboxNLP</abbr>
    
  
  </div>

  <div id="li-etal-2020-linguistically" class="col-sm-8">
    
      <div class="title">Linguistically-Informed Transformations (LIT): A Method for Automatically Generating Contrast Sets</div>
      <div class="author">
        
          
            
              
                
                  Li, Chuanrong*,
                
              
            
          
        
          
            
              
                
                  Shengshuo, Lin*,
                
              
            
          
        
          
            
              
                
                  Liu, Zeyu*,
                
              
            
          
        
          
            
              
                
                  Wu, Xinyi*,
                
              
            
          
        
          
            
              
                <em>Zhou, Xuhui*</em>,
              
            
          
        
          
            
              
                
                  and Steinert-Threlkeld, Shane
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.aclweb.org/anthology/2020.blackboxnlp-1.12" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Although large-scale pretrained language models, such as BERT and RoBERTa, have achieved superhuman performance on in-distribution test sets, their performance suffers on out-of-distribution test sets (e.g., on contrast sets). Building contrast sets often requires human-expert annotation, which is expensive and hard to create on a large scale. In this work, we propose a Linguistically-Informed Transformation (LIT) method to automatically generate contrast sets, which enables practitioners to explore linguistic phenomena of interests as well as compose different phenomena. Experimenting with our method on SNLI and MNLI shows that current pretrained language models, although being claimed to contain sufficient linguistic knowledge, struggle on our automatically generated contrast sets. Furthermore, we improve modelsâ€™ performance on the contrast sets by applying LIT to augment the training data, without affecting performance on the original data.</p>
    </div>
    

    <div id="ali-etal-2020-linguistically" style="display: none;">
    <pre>@inproceedings{li-etal-2020-linguistically,
  title = {Linguistically-Informed Transformations ({LIT}): A Method for Automatically Generating Contrast Sets},
  author = {Li, Chuanrong* and Shengshuo, Lin* and Liu, Zeyu* and Wu, Xinyi* and Zhou, Xuhui* and Steinert-Threlkeld, Shane},
  abbr = {BlackboxNLP},
  booktitle = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  month = nov,
  year = {2020},
  address = {Online},
  publisher = {Association for Computational Linguistics},
  html = {https://www.aclweb.org/anthology/2020.blackboxnlp-1.12},
  pages = {126--135}
}
</pre>
    </div>
    <script>
    function toggleBibtexli-etal-2020-linguistically(parameter) {
        var x= document.getElementById('ali-etal-2020-linguistically');
        if (x.style.display === 'none') {
            x.style.display = 'block';
        } else {
            x.style.display = 'none';
        }
    }
    </script>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">EMNLP</abbr>
    
  
  </div>

  <div id="zhou-etal-2020-multilevel" class="col-sm-8">
    
      <div class="title">Multilevel Text Alignment with Cross-Document Attention</div>
      <div class="author">
        
          
            
              
                <em>Zhou, Xuhui</em>,
              
            
          
        
          
            
              
                
                  Pappas, Nikolaos,
                
              
            
          
        
          
            
              
                
                  and Smith, Noah A.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.aclweb.org/anthology/2020.emnlp-main.407" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
      <a href="https://xuhuizhou.github.io/Multilevel-Text-Alignment/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Text alignment finds application in tasks such as citation recommendation and plagiarism detection. Existing alignment methods operate at a single, predefined level and cannot learn to align texts at, for example, sentence \textitand document levels. We propose a new learning approach that equips previously established hierarchical attention encoders for representing documents with a cross-document attention component, enabling structural comparisons across different levels (document-to-document and sentence-to-document). Our component is weakly supervised from document pairs and can align at multiple levels. Our evaluation on predicting document-to-document relationships and sentence-to-document relationships on the tasks of citation recommendation and plagiarism detection shows that our approach outperforms previously established hierarchical, attention encoders based on recurrent and transformer contextualization that are unaware of structural correspondence between documents.</p>
    </div>
    

    <div id="azhou-etal-2020-multilevel" style="display: none;">
    <pre>@inproceedings{zhou-etal-2020-multilevel,
  title = {Multilevel Text Alignment with Cross-Document Attention},
  author = {Zhou, Xuhui and Pappas, Nikolaos and Smith, Noah A.},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  abbr = {EMNLP},
  year = {2020},
  address = {Online},
  publisher = {Association for Computational Linguistics},
  html = {https://www.aclweb.org/anthology/2020.emnlp-main.407},
  pages = {5012--5025},
  website = {https://xuhuizhou.github.io/Multilevel-Text-Alignment/}
}
</pre>
    </div>
    <script>
    function toggleBibtexzhou-etal-2020-multilevel(parameter) {
        var x= document.getElementById('azhou-etal-2020-multilevel');
        if (x.style.display === 'none') {
            x.style.display = 'block';
        } else {
            x.style.display = 'none';
        }
    }
    </script>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ACL SRW</abbr>
    
  
  </div>

  <div id="zhou-etal-2020-rpd" class="col-sm-8">
    
      <div class="title">RPD: A Distance Function Between Word Embeddings</div>
      <div class="author">
        
          
            
              
                <em>Zhou, Xuhui</em>,
              
            
          
        
          
            
              
                
                  Huang, Shujian,
                
              
            
          
        
          
            
              
                
                  and Zheng, Zaixiang
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.aclweb.org/anthology/2020.acl-srw.7" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>It is well-understood that different algorithms, training processes, and corpora produce different word embeddings. However, less is known about the relation between different embedding spaces, i.e. how far different sets of em-beddings deviate from each other. In this paper, we propose a novel metric called Relative Pairwise Inner Product Distance (RPD) to quantify the distance between different sets of word embeddings. This unitary-invariant metric has a unified scale for comparing different sets of word embeddings. Based on the properties of RPD, we study the relations of word embeddings of different algorithms systematically and investigate the influence of different training processes and corpora. The results shed light on the poorly understood word embeddings and justify RPD as a measure of the distance of embedding space.</p>
    </div>
    

    <div id="azhou-etal-2020-rpd" style="display: none;">
    <pre>@inproceedings{zhou-etal-2020-rpd,
  title = {{RPD}: A Distance Function Between Word Embeddings},
  author = {Zhou, Xuhui and Huang, Shujian and Zheng, Zaixiang},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop},
  abbr = {ACL SRW},
  year = {2020},
  address = {Online},
  publisher = {Association for Computational Linguistics},
  html = {https://www.aclweb.org/anthology/2020.acl-srw.7},
  doi = {10.18653/v1/2020.acl-srw.7},
  pages = {42--50}
}
</pre>
    </div>
    <script>
    function toggleBibtexzhou-etal-2020-rpd(parameter) {
        var x= document.getElementById('azhou-etal-2020-rpd');
        if (x.style.display === 'none') {
            x.style.display = 'block';
        } else {
            x.style.display = 'none';
        }
    }
    </script>

  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AAAI</abbr>
    
  
  </div>

  <div id="ZHOU2019EvaluatingCI" class="col-sm-8">
    
      <div class="title">Evaluating Commonsense in Pre-trained Language Models</div>
      <div class="author">
        
          
            
              
                <em>Zhou, Xuhui</em>,
              
            
          
        
          
            
              
                
                  Zhang, Y.,
                
              
            
          
        
          
            
              
                
                  Cui, Leyang,
                
              
            
          
        
          
            
              
                
                  and Huang, Dandan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the AAAI Conference on Artificial Intelligence, 34(05)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://ojs.aaai.org//index.php/AAAI/article/view/6523" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <div id="aZHOU2019EvaluatingCI" style="display: none;">
    <pre>@inproceedings{ZHOU2019EvaluatingCI,
  title = {Evaluating Commonsense in Pre-trained Language Models},
  author = {Zhou, Xuhui and Zhang, Y. and Cui, Leyang and Huang, Dandan},
  html = {https://ojs.aaai.org//index.php/AAAI/article/view/6523},
  year = {2020},
  volume = {abs/1911.11931},
  abbr = {AAAI},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence, 34(05)}
}
</pre>
    </div>
    <script>
    function toggleBibtexZHOU2019EvaluatingCI(parameter) {
        var x= document.getElementById('aZHOU2019EvaluatingCI');
        if (x.style.display === 'none') {
            x.style.display = 'block';
        } else {
            x.style.display = 'none';
        }
    }
    </script>

  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Xuhui  Zhou.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
